{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbf63e8b-e216-4ecd-a902-d17f05108c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "from os.path                       import join, basename\n",
    "from skimage.transform             import resize\n",
    "from matplotlib.pyplot             import imread\n",
    "from datetime                      import datetime\n",
    "\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras.models       import Sequential\n",
    "from tensorflow.keras.layers       import Dense, Activation, Flatten, Dropout\n",
    "from tensorflow.keras.layers       import MaxPooling2D\n",
    "from tensorflow.keras.layers       import Conv2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers   import Adam\n",
    "from tensorflow.keras.layers       import LeakyReLU\n",
    "from livelossplot                  import PlotLossesKeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f67122e5-5309-4e99-8265-20ea1c40c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, X,  y):\n",
    "    \"Return the accuracy of model on Inputs X and labels y.\"\n",
    "    predict_x =model.predict(X) \n",
    "    y_hat = np.argmax(predict_x, axis=1)\n",
    "    #y_hat = model.predict_classes(X, verbose=0)\n",
    "    n_correct = (np.array(y_hat) == np.array(y)).sum()\n",
    "    return n_correct / float(y.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38519732-3322-4a4e-95d2-41a0717c0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod(z):\n",
    "    \"Return the product z[0] * z[1] * ... * z[-1].\"\n",
    "    # Jude get a complaint on this so rewrote: return reduce(lambda x, y: x*y, z, 1)\n",
    "    result = 1\n",
    "    for i in range(0, len(z)):\n",
    "        result *= z[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b50c64-79d5-4e42-816a-bc2ce23db641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_course_images(directory, image_size):\n",
    "    \"\"\"\n",
    "    load the cs638 course images and labels from a directory.\n",
    "    image_size = (L, W) the length and width of returned images\n",
    "    \n",
    "    return X, y, y_onehot\n",
    "    \n",
    "        X - a numpy ndarray with shape (n, L, W, 4). \n",
    "            n is the # of images. \n",
    "            L,W is imageIndex length and width\n",
    "            4 is for the RGB + Grayscale channels\n",
    "            \n",
    "        y - 1D numpy array of imageIndex labels encoded as integer between 0 and 5\n",
    "        \n",
    "        y_onehot - one-hot encoding of y as numpy array with shape (n, 6)\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    files  = [f for f in os.listdir(directory) if f.endswith(\"jpg\")]\n",
    "    shape  = [len(files)] + [image_size, image_size, 4]\n",
    "    X      = np.zeros(shape = shape) + np.nan  # Put a NaN in each cell to make sure we replace it below?\n",
    "    \n",
    "    for imageIndex, f in enumerate(files):\n",
    "        I = imread(\"{}/{}\".format(directory, f))\n",
    "        I = resize(I, [image_size, image_size])\n",
    "        X[imageIndex, :, :, 0:3] = I / 255.0                # rgb  channels\n",
    "        X[imageIndex, :, :, 3]   = (I.mean(axis=2) / 255.0) # gray channel\n",
    "        labels.append(f.split(\"_\")[0]) # Pull the LABEL out of the image name (i.e., all the characters before the first underscore).\n",
    "        \n",
    "    assert np.isnan(X).sum() == 0 # Make sure no NaNs remain in the data.\n",
    "    y        = np.array([LABELS.index(lbl) for lbl in labels]) # Collect all the LABELs.\n",
    "    y_onehot = np.zeros((X.shape[0], len(LABELS))) # Now need to convert to a 'one hot' representation.\n",
    "    for rowIndex, colIndex in enumerate(y):  # This will produce ( (0, y(0)), (1, y(1)), ..., (n, y(n)) ) where n+1 is the number of images.\n",
    "        y_onehot[rowIndex, colIndex] = 1 # For each image, set one output unit to 1.\n",
    "        \n",
    "    return X, y, y_onehot, [join(directory, f) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f9a529-5311-4bcc-8706-2a984c66606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the directory contain all the images\n",
    "IMG_DIR           = \"./data/images\"\n",
    "\n",
    "LABELS            = ['airplanes', 'butterfly', 'flower', 'grand', 'starfish', 'watch']   \n",
    "\n",
    "imageDimension    = 32\n",
    "numberOfColors    =   4 # R, G, B, and Gray\n",
    "epochsToRun       = 100\n",
    "batch_size        =  10 # how many gradients we collect before updating weights\n",
    "platesConv1       =  16\n",
    "platesConv2       =  16\n",
    "kernelSizeConv1   =   4\n",
    "kernelSizePool1   =   2\n",
    "kernelSizeConv2   =   4\n",
    "kernelSizePool2   =   2\n",
    "strideConv1       =   1 # same for both x and y dimensions\n",
    "stridePool1       =   2 # same for both x and y dimensions\n",
    "strideConv2       =   1 # same for both x and y dimensions\n",
    "stridePool2       =   2 # same for both x and y dimensions\n",
    "zeroPaddingConv1  =   1 # same for both x and y dimensions (this is padding of the INPUT image)\n",
    "zeroPaddingPool1  =   1 # same for both x and y dimensions (this is padding of the CONV1 image)\n",
    "zeroPaddingConv2  =   1 # same for both x and y dimensions (this is padding of the POOL1 image)\n",
    "zeroPaddingPool2  =   1 # same for both x and y dimensions (this is padding of the CONV2 image)\n",
    "input_dropoutProb =   0.05\n",
    "conv1_dropoutProb =   0.50\n",
    "pool1_dropoutProb =   0.00\n",
    "conv2_dropoutProb =   0.50\n",
    "pool2_dropoutProb =   0.00\n",
    "final_dropoutProb =   0.50\n",
    "numberOfFinalHUs  = 128\n",
    "numberOfClasses   = len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4ed604a-2bc7-4f66-aecc-4f2c6f8fd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping.\n",
    "confusionTestsetAtBestTuneset = np.zeros((numberOfClasses, numberOfClasses))\n",
    "bestTuneSetEpoch     = np.nan\n",
    "bestTuneSetAcc       = 0\n",
    "testSetAccAtBestTune = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49fb7535-9849-4cb8-8d0a-c8d9741a5aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 554 training examples.\n",
      "There are 180 tuning examples.\n",
      "There are 178 testing examples.\n"
     ]
    }
   ],
   "source": [
    "# Read in the images.  Only the TEST examples really need to be kept (at the end a web page of testset errors produced).\n",
    "X_train, y_train, y_onehot_train, img_files_train = load_course_images(directory=\"{}/trainset\".format(IMG_DIR), image_size=imageDimension)\n",
    "X_tune,  y_tune,  y_onehot_tune,  img_files_tune  = load_course_images(directory=\"{}/tuneset\".format( IMG_DIR), image_size=imageDimension)\n",
    "X_test,  y_test,  y_onehot_test,  img_files_test  = load_course_images(directory=\"{}/testset\".format( IMG_DIR), image_size=imageDimension)\n",
    "\n",
    "print(\"There are {:,} training examples.\".format(len(X_train)))\n",
    "print(\"There are {:,} tuning examples.\".format(  len(X_tune)))\n",
    "print(\"There are {:,} testing examples.\".format( len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b830eea7-6374-4963-a17c-f8d229ee8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architecture  See https://keras.io/getting-started/sequential-model-guide/\n",
    "model = Sequential()\n",
    "#model.add(Dropout(input_dropoutProb)) # Can't specify dropOut for input units?  See https://github.com/fchollet/keras/issues/96\n",
    "\n",
    "leakyReLUtoUse = LeakyReLU(alpha = 0.1)\n",
    "\n",
    "model.add(Conv2D(platesConv1, \n",
    "                 kernel_size = kernelSizeConv1,\n",
    "                 input_shape = [imageDimension, imageDimension, numberOfColors],\n",
    "                 data_format = \"channels_last\", # Says that the color channels are LAST.\n",
    "                 strides     = strideConv1, \n",
    "                 padding     = \"valid\", # I'm not sure what this does?  Says zero padding is ok????\n",
    "                 use_bias    = True))\n",
    "\n",
    "model.add(leakyReLUtoUse); # Have to add as a layer, not as an argument to Conv2D.  See https://github.com/fchollet/keras/issues/3380\n",
    "model.add(ZeroPadding2D(padding = zeroPaddingConv1, data_format = \"channels_last\"))\n",
    "model.add(Dropout(conv1_dropoutProb)) \n",
    "\n",
    "model.add(MaxPooling2D(pool_size = kernelSizePool1, strides = stridePool1, padding = 'valid'))\n",
    "model.add(Dropout(pool1_dropoutProb))\n",
    "model.add(ZeroPadding2D(padding  = zeroPaddingPool1))\n",
    "\n",
    "model.add(Conv2D(platesConv2, \n",
    "                 kernel_size = kernelSizeConv2,\n",
    "                 strides     = strideConv2, \n",
    "                 padding     = \"valid\", # zero padding????\n",
    "                 use_bias    = True))\n",
    "\n",
    "model.add(leakyReLUtoUse); # Have to add as a layer, not as an argument to Conv2D.  See https://github.com/fchollet/keras/issues/3380\n",
    "model.add(Dropout(conv2_dropoutProb))\n",
    "model.add(ZeroPadding2D(padding=  zeroPaddingConv2))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = kernelSizePool2, strides = stridePool2, padding = 'valid'))\n",
    "model.add(Dropout(pool2_dropoutProb))\n",
    "model.add(ZeroPadding2D(padding  = zeroPaddingPool2))\n",
    "\n",
    "model.add(Flatten()) # Flattens the last MAX POOL layer so can fully connect to the final HU layer.\n",
    "\n",
    "model.add(Dense(units = numberOfFinalHUs))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(final_dropoutProb))\n",
    "\n",
    "model.add(Dense(units = numberOfClasses))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb9acf50-2d2e-47b9-8902-506c0d46d55a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m numberOfWeights \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tw \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainable_weights:\n\u001b[0;32m----> 4\u001b[0m      numberOfWeights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod([dim\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m tw\u001b[38;5;241m.\u001b[39mget_shape()])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model has \u001b[39m\u001b[38;5;132;01m{:,}\u001b[39;00m\u001b[38;5;124m trainable weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(numberOfWeights))\n",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m numberOfWeights \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tw \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainable_weights:\n\u001b[0;32m----> 4\u001b[0m      numberOfWeights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prod([\u001b[43mdim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m tw\u001b[38;5;241m.\u001b[39mget_shape()])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model has \u001b[39m\u001b[38;5;132;01m{:,}\u001b[39;00m\u001b[38;5;124m trainable weights.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(numberOfWeights))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "# Report the size of the model.\n",
    "numberOfWeights = 0\n",
    "for tw in model.trainable_weights:\n",
    "     numberOfWeights += prod([dim.value for dim in tw.get_shape()])\n",
    "print()\n",
    "print(\"The model has {:,} trainable weights.\".format(numberOfWeights))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "074a1a5e-db3a-42a3-91e9-5e02e19f9bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizerToUse \u001b[38;5;241m=\u001b[39m Adam() \u001b[38;5;66;03m# Use the defaults (https://keras.io/optimizers/).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m optimizerToUse, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;66;03m# Had been 'rmsprop' (good for recurrent nets).\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mPlotLossesKeras\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/ln/m6fjn42s1kj2wh1fww1brzlh0000gn/T/__autograph_generated_filehquamx5s.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/Users/scheong/devel/conda/tensorflow-env/env/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n"
     ]
    }
   ],
   "source": [
    "### Train the model.\n",
    "\n",
    "optimizerToUse = Adam() # Use the defaults (https://keras.io/optimizers/).\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizerToUse, metrics = ['accuracy']) # Had been 'rmsprop' (good for recurrent nets).\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[PlotLossesKeras()],\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f28bb0b-0a3c-4f5b-8a15-efd1d16a2e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
